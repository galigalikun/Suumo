{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.1-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.1\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/3.0.1/libexec/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.2.0-cp39-cp39-macosx_10_9_x86_64.whl (10.7 MB)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/Cellar/jupyterlab/3.0.1/libexec/lib/python3.9/site-packages (from pandas) (2020.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/Cellar/jupyterlab/3.0.1/libexec/lib/python3.9/site-packages (from pandas) (2.8.1)\n",
      "Collecting numpy>=1.16.5\n",
      "  Using cached numpy-1.19.5-cp39-cp39-macosx_10_9_x86_64.whl (15.6 MB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/Cellar/jupyterlab/3.0.1/libexec/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: numpy, pandas\n",
      "Successfully installed numpy-1.19.5 pandas-1.2.0\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/3.0.1/libexec/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! /usr/local/Cellar/jupyterlab/3.0.1/libexec/bin/pip3.9 install beautifulsoup4\n",
    "! /usr/local/Cellar/jupyterlab/3.0.1/libexec/bin/pip3.9 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n",
      "next13118\n"
     ]
    }
   ],
   "source": [
    "#必要なライブラリをインポート\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import threading\n",
    "\n",
    "class ScrapingThreading(threading.Thread):\n",
    "    def __init__(self, sc):\n",
    "        self.sc = str(sc)\n",
    "        threading.Thread.__init__(self)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.sc\n",
    "\n",
    "    def run(self):        \n",
    "#URL（賃貸住宅情報 検索結果の1ページ目）sc ex)13121 東京都足立区\n",
    "# https://suumo.jp/jj/chintai/ichiran/FR301FC001/?ar=030&bs=040&ta=13&sc=13123&cb=0.0&ct=9999999&et=9999999&cn=9999999&mb=0&mt=9999999&shkr1=03&shkr2=03&shkr3=03&shkr4=03&fw2=&srch_navi=1\n",
    "        url = 'http://suumo.jp/jj/chintai/ichiran/FR301FC001/?ar=030&bs=040&ta=13&sc='+ self.sc + '&cb=0.0&ct=9999999&et=9999999&cn=9999999&mb=0&mt=9999999&shkr1=03&shkr2=03&shkr3=03&shkr4=03&fw2=&srch_navi=1'\n",
    "\n",
    "        #データ取得\n",
    "        result = requests.get(url)\n",
    "        c = result.content\n",
    "\n",
    "        #HTMLを元に、オブジェクトを作る\n",
    "        soup = BeautifulSoup(c)\n",
    "\n",
    "        #物件リストの部分を切り出し\n",
    "        summary = soup.find(\"div\",{'id':'js-bukkenList'})\n",
    "\n",
    "        #ページ数を取得\n",
    "        body = soup.find(\"body\")\n",
    "        pages = body.find_all(\"div\",{'class':'pagination pagination_set-nav'})\n",
    "        pages_text = str(pages)\n",
    "        pages_split = pages_text.split('</a></li>\\n</ol>')\n",
    "        pages_split0 = pages_split[0]\n",
    "        pages_split1 = pages_split0[-3:]\n",
    "        pages_split2 = pages_split1.replace('>','')\n",
    "        pages_split3 = int(pages_split2)\n",
    "\n",
    "        #URLを入れるリスト\n",
    "        urls = []\n",
    "\n",
    "        #1ページ目を格納\n",
    "        urls.append(url)\n",
    "\n",
    "        #2ページ目から最後のページまでを格納\n",
    "        for i in range(pages_split3-1):\n",
    "            pg = str(i+2)\n",
    "            url_page = url + '&pn=' + pg\n",
    "            urls.append(url_page)\n",
    "\n",
    "        name = [] #マンション名\n",
    "        address = [] #住所\n",
    "        locations0 = [] #立地1つ目（最寄駅/徒歩~分）\n",
    "        locations1 = [] #立地2つ目（最寄駅/徒歩~分）\n",
    "        locations2 = [] #立地3つ目（最寄駅/徒歩~分）\n",
    "        age = [] #築年数\n",
    "        height = [] #建物高さ\n",
    "        floor = [] #階\n",
    "        rent = [] #賃料\n",
    "        admin = [] #管理費\n",
    "        deposit = [] #敷\n",
    "        gratuity= [] #礼\n",
    "#         /保証/敷引,償却\n",
    "        floor_plan = [] #間取り\n",
    "        area = [] #専有面積\n",
    "\n",
    "        #各ページで以下の動作をループ\n",
    "        for url in urls:\n",
    "            #物件リストを切り出し\n",
    "            result = requests.get(url)\n",
    "            c = result.content\n",
    "            soup = BeautifulSoup(c)\n",
    "            summary = soup.find(\"div\",{'id':'js-bukkenList'})\n",
    "\n",
    "            #マンション名、住所、立地（最寄駅/徒歩~分）、築年数、建物高さが入っているcassetteitemを全て抜き出し\n",
    "            cassetteitems = summary.find_all(\"div\",{'class':'cassetteitem'})\n",
    "\n",
    "            #各cassetteitemsに対し、以下の動作をループ\n",
    "            for i in range(len(cassetteitems)):\n",
    "                #各建物から売りに出ている部屋数を取得\n",
    "                tbodies = cassetteitems[i].find_all('tbody')\n",
    "\n",
    "                #マンション名取得\n",
    "                subtitle = cassetteitems[i].find_all(\"div\",{\n",
    "                    'class':'cassetteitem_content-title'})\n",
    "                subtitle = str(subtitle)\n",
    "                subtitle_rep = subtitle.replace(\n",
    "                    '[<div class=\"cassetteitem_content-title\">', '')\n",
    "                subtitle_rep2 = subtitle_rep.replace(\n",
    "                    '</div>]', '')\n",
    "\n",
    "                #住所取得\n",
    "                subaddress = cassetteitems[i].find_all(\"li\",{\n",
    "                    'class':'cassetteitem_detail-col1'})\n",
    "                subaddress = str(subaddress)\n",
    "                subaddress_rep = subaddress.replace(\n",
    "                    '[<li class=\"cassetteitem_detail-col1\">', '')\n",
    "                subaddress_rep2 = subaddress_rep.replace(\n",
    "                    '</li>]', '')\n",
    "\n",
    "                #部屋数だけ、マンション名と住所を繰り返しリストに格納（部屋情報と数を合致させるため）\n",
    "                for y in range(len(tbodies)):\n",
    "                    name.append(subtitle_rep2)\n",
    "                    address.append(subaddress_rep2)\n",
    "\n",
    "                #立地を取得\n",
    "                sublocations = cassetteitems[i].find_all(\"li\",{\n",
    "                    'class':'cassetteitem_detail-col2'})\n",
    "\n",
    "                #立地は、1つ目から3つ目までを取得（4つ目以降は無視）\n",
    "                for x in sublocations:\n",
    "                    cols = x.find_all('div')\n",
    "                    for i in range(len(cols)):\n",
    "                        text = cols[i].find(text=True)\n",
    "                        for y in range(len(tbodies)):\n",
    "                            if i == 0:\n",
    "                                locations0.append(text)\n",
    "                            elif i == 1:\n",
    "                                locations1.append(text)\n",
    "                            elif i == 2:\n",
    "                                locations2.append(text)\n",
    "\n",
    "                #築年数と建物高さを取得\n",
    "                tbodies = cassetteitems[i].find_all('tbody')\n",
    "                col3 = cassetteitems[i].find_all(\"li\",{\n",
    "                    'class':'cassetteitem_detail-col3'})\n",
    "                for x in col3:\n",
    "                    cols = x.find_all('div')\n",
    "                    for i in range(len(cols)):\n",
    "                        text = cols[i].find(text=True)\n",
    "                        for y in range(len(tbodies)):\n",
    "                            if i == 0:\n",
    "                                age.append(text)\n",
    "                            else:\n",
    "                                height.append(text)\n",
    "\n",
    "            #階、賃料、管理費、敷/礼/保証/敷引,償却、間取り、専有面積が入っているtableを全て抜き出し\n",
    "            tables = summary.find_all('table')\n",
    "\n",
    "            #各建物（table）に対して、売りに出ている部屋（row）を取得\n",
    "            rows = []\n",
    "            for i in range(len(tables)):\n",
    "                rows.append(tables[i].find_all('tr'))\n",
    "\n",
    "            #各部屋に対して、tableに入っているtext情報を取得し、dataリストに格納\n",
    "            data = []\n",
    "            for row in rows:\n",
    "                for tr in row:\n",
    "                    cols = tr.find_all('td')\n",
    "                    for td in cols:\n",
    "                        lis = td.find_all('li')\n",
    "                        if len(lis) == 0:\n",
    "                            text = td.find(text=True)\n",
    "                            data.append(text)                 \n",
    "                        for li in td.find_all('li'):\n",
    "                            text = li.find(text=True)\n",
    "                            data.append(text)                              \n",
    "\n",
    "\n",
    "            #dataリストから、階、賃料、管理費、敷/礼/保証/敷引,償却、間取り、専有面積を順番に取り出す\n",
    "            index = 0\n",
    "            for item in data:\n",
    "                if '階' in item:\n",
    "                    floor.append(data[index])\n",
    "                    rent.append(data[index+1])\n",
    "                    admin.append(data[index+2])\n",
    "                    deposit.append(data[index+3])\n",
    "                    gratuity.append(data[index+4])\n",
    "                    floor_plan.append(data[index+5])\n",
    "                    area.append(data[index+6])\n",
    "                index +=1\n",
    "\n",
    "            #プログラムを4-10秒間停止する（スクレイピングマナー）\n",
    "            sleep_seconds = random.randint(4, 10)\n",
    "            time.sleep(sleep_seconds)\n",
    "            print('next'+self.sc)\n",
    "\n",
    "        #各リストをシリーズ化\n",
    "        name = Series(name)\n",
    "        address = Series(address)\n",
    "        locations0 = Series(locations0)\n",
    "        locations1 = Series(locations1)\n",
    "        locations2 = Series(locations2)\n",
    "        age = Series(age)\n",
    "        height = Series(height)\n",
    "        floor = Series(floor)\n",
    "        rent = Series(rent)\n",
    "        admin = Series(admin)\n",
    "        deposit = Series(deposit)\n",
    "        gratuity = Series(gratuity)\n",
    "        floor_plan = Series(floor_plan)\n",
    "        area = Series(area)\n",
    "\n",
    "        #各シリーズをデータフレーム化\n",
    "        suumo_df = pd.concat([name, address, locations0, locations1,\n",
    "                              locations2, age, height,floor,rent,admin,deposit,gratuity,floor_plan,area],axis=1)\n",
    "\n",
    "        #カラム名\n",
    "        suumo_df.columns=['マンション名','住所','立地1','立地2','立地3','築年数','建物高さ','階','賃料','管理費',\n",
    "                          '敷','礼','間取り','専有面積']\n",
    "\n",
    "        #csvファイルとして保存\n",
    "        suumo_df.to_csv('suumo_'+self.sc+'.csv', sep = '\\t',encoding='utf-16')\n",
    "\n",
    "scraping_list = ['11101', '11102', '11103', '11104', '11105', '11106', '11107', '11108' , '11109', '11110'] #さいたま市 \n",
    "scraping_list.extend(['11203']) # さいたま市以外\n",
    "scraping_list.extend(['13101', '13102', '13103', '13104', '13105', '13113']) # 都心\n",
    "scraping_list.extend(['13106', '13107', '13108', '13118', '13121', '13122', '13123']) # 23区東部\n",
    "scraping_list.extend(['13109', '13110', '13111', '13112']) # 23区南部\n",
    "scraping_list.extend(['13114', '13115', '13120']) # 23区西区\n",
    "scraping_list.extend(['13116', '13117', '13119']) # 23区北区\n",
    "\n",
    "\n",
    "thread_list = []\n",
    "for sc in scraping_list:\n",
    "    if not os.path.exists('suumo_'+sc+'.csv'):\n",
    "        thread = ScrapingThreading(sc)\n",
    "        thread.start()\n",
    "        thread_list.append(thread)\n",
    "    \n",
    "for thread in thread_list:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
